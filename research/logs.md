# Ideas

## Sentence Similarity Baseline
| Run        | Accuracy   | 
|--------------|:----------:|
| 0.0 | 84.3 |
| 0.1 | 00.0 |  

# Experiments 
## Architecture 

### Network Weights Initialization

### Batch Normalization

### Character BiLSTM
The authors of the paper used a vanilla LSTM for character-level embeddings. Let's see if a BiLSTM does any better. 

### GRU
Using GRU cell instead of BiLSTM.

### Number of Perspectives

### Increased Hidden Layers in Char LSTM

### Using ULMFiT Vectors instead of GloVe

## Activation Functions
Experimenting with different activation functions. 

### TanH

### Swish
